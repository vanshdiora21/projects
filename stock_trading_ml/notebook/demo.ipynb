{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Trading Strategy - Demo Notebook\n",
    "\n",
    "This notebook demonstrates the complete workflow of the ML-driven trading strategy.\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Data Loading**: Fetch stock price data and engineer features\n",
    "2. **Model Training**: Train multiple ML models\n",
    "3. **Strategy Backtesting**: Run historical simulation\n",
    "4. **Performance Analysis**: Evaluate results and generate plots\n",
    "5. **Model Comparison**: Compare different approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"üìä ML Trading Strategy Demo\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "with open('../config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "# Modify config for demo (smaller dataset)\n",
    "config['data']['tickers'] = ['AAPL', 'GOOGL']  # Use fewer tickers for demo\n",
    "config['data']['start_date'] = '2022-01-01'\n",
    "config['data']['end_date'] = '2024-01-01'\n",
    "config['models']['models_to_train'] = ['random_forest', 'xgboost']  # Faster models\n",
    "\n",
    "print(\"üìã Configuration loaded:\")\n",
    "print(f\"Tickers: {config['data']['tickers']}\")\n",
    "print(f\"Period: {config['data']['start_date']} to {config['data']['end_date']}\")\n",
    "print(f\"Models: {config['models']['models_to_train']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data loading modules\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from data.data_loader import load_and_prepare_data\n",
    "\n",
    "# Load data\n",
    "print(\"üì• Loading stock data...\")\n",
    "raw_data, processed_data = load_and_prepare_data(config)\n",
    "\n",
    "print(f\"‚úÖ Data loaded for {len(processed_data)} tickers\")\n",
    "for ticker, df in processed_data.items():\n",
    "    print(f\"  - {ticker}: {len(df)} records, {len(df.columns)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine sample data\n",
    "sample_ticker = list(processed_data.keys())[0]\n",
    "sample_df = processed_data[sample_ticker]\n",
    "\n",
    "print(f\"üìä Sample data for {sample_ticker}:\")\n",
    "print(f\"Shape: {sample_df.shape}\")\n",
    "print(f\"Date range: {sample_df['date'].min()} to {sample_df['date'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "display_cols = ['date', 'close', 'return_1d', 'sma_20', 'rsi_14', 'target']\n",
    "available_cols = [col for col in display_cols if col in sample_df.columns]\n",
    "sample_df[available_cols].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot price and technical indicators\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Price and moving averages\n",
    "axes[0, 0].plot(sample_df['date'], sample_df['close'], label='Close Price', linewidth=2)\n",
    "if 'sma_20' in sample_df.columns:\n",
    "    axes[0, 0].plot(sample_df['date'], sample_df['sma_20'], label='SMA 20', alpha=0.7)\n",
    "if 'sma_50' in sample_df.columns:\n",
    "    axes[0, 0].plot(sample_df['date'], sample_df['sma_50'], label='SMA 50', alpha=0.7)\n",
    "axes[0, 0].set_title(f'{sample_ticker} Price and Moving Averages')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Returns distribution\n",
    "if 'return_1d' in sample_df.columns:\n",
    "    returns = sample_df['return_1d'].dropna()\n",
    "    axes[0, 1].hist(returns, bins=50, alpha=0.7, edgecolor='black')\n",
    "    axes[0, 1].axvline(returns.mean(), color='red', linestyle='--', label=f'Mean: {returns.mean():.4f}')\n",
    "    axes[0, 1].set_title('Daily Returns Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "if 'rsi_14' in sample_df.columns:\n",
    "    axes[1, 0].plot(sample_df['date'], sample_df['rsi_14'], linewidth=1)\n",
    "    axes[1, 0].axhline(70, color='red', linestyle='--', alpha=0.7, label='Overbought')\n",
    "    axes[1, 0].axhline(30, color='green', linestyle='--', alpha=0.7, label='Oversold')\n",
    "    axes[1, 0].set_title('RSI (14-day)')\n",
    "    axes[1, 0].set_ylim(0, 100)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Target distribution\n",
    "if 'target' in sample_df.columns:\n",
    "    target_counts = sample_df['target'].value_counts()\n",
    "    axes[1, 1].bar(target_counts.index, target_counts.values, alpha=0.7)\n",
    "    axes[1, 1].set_title('Target Distribution')\n",
    "    axes[1, 1].set_xlabel('Target (0=Down, 1=Up)')\n",
    "    axes[1, 1].set_ylabel('Count')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ml_models import MLModelManager\n",
    "from data.data_loader import DataLoader\n",
    "\n",
    "# Prepare training data\n",
    "print(\"üéØ Preparing training data...\")\n",
    "loader = DataLoader(config)\n",
    "\n",
    "# Combine data from all tickers\n",
    "combined_features = []\n",
    "combined_targets = []\n",
    "\n",
    "for ticker, df in processed_data.items():\n",
    "    X, y = loader.prepare_ml_data(df)\n",
    "    \n",
    "    # Remove rows with NaN targets\n",
    "    valid_mask = ~y.isna() & ~X.isna().any(axis=1)\n",
    "    X_clean = X[valid_mask]\n",
    "    y_clean = y[valid_mask]\n",
    "    \n",
    "    if len(X_clean) > 10:\n",
    "        combined_features.append(X_clean)\n",
    "        combined_targets.append(y_clean)\n",
    "\n",
    "# Combine all data\n",
    "X_train = pd.concat(combined_features, ignore_index=True)\n",
    "y_train = pd.concat(combined_targets, ignore_index=True)\n",
    "\n",
    "print(f\"Training dataset: {X_train.shape[0]} samples, {X_train.shape[asset:1]} features\")\n",
    "print(f\"Target distribution: {y_train.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models\n",
    "print(\"ü§ñ Training ML models...\")\n",
    "\n",
    "model_manager = MLModelManager(config)\n",
    "model_manager.initialize_models()\n",
    "trained_models = model_manager.train_models(X_train, y_train)\n",
    "\n",
    "print(\"\\nüìà Training Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for model_name, metrics in model_manager.performance_metrics.items():\n",
    "    print(f\"{model_name.upper()}:\")\n",
    "    print(f\"  Training Accuracy: {metrics.get('train_accuracy', 0):.4f}\")\n",
    "    print(f\"  Validation Accuracy: {metrics.get('val_accuracy', 0):.4f}\")\n",
    "    if 'roc_auc' in metrics:\n",
    "        print(f\"  ROC AUC: {metrics.get('roc_auc', 0):.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze feature importance for tree-based models\n",
    "for model_name in ['random_forest', 'xgboost']:\n",
    "    if model_name in trained_models:\n",
    "        try:\n",
    "            importance_df = model_manager.get_feature_importance(model_name)\n",
    "            if not importance_df.empty:\n",
    "                # Plot top 15 features\n",
    "                top_features = importance_df.head(15)\n",
    "                \n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.barh(range(len(top_features)), top_features['importance'], alpha=0.8)\n",
    "                plt.yticks(range(len(top_features)), top_features['feature'])\n",
    "                plt.xlabel('Importance Score')\n",
    "                plt.title(f'Top 15 Feature Importance - {model_name.replace(\"_\", \" \").title()}')\n",
    "                plt.gca().invert_yaxis()\n",
    "                plt.grid(True, alpha=0.3)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                print(f\"\\nüìä Top 10 Features for {model_name}:\")\n",
    "                for i, row in top_features.head(10).iterrows():\n",
    "                    print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not analyze feature importance for {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtest.backtester import Backtester\n",
    "\n",
    "# Run backtesting\n",
    "print(\"üìä Running backtesting...\")\n",
    "\n",
    "# Adjust backtest parameters for demo\n",
    "config['backtest']['walk_forward']['training_window'] = 126  # 6 months\n",
    "config['backtest']['walk_forward']['validation_window'] = 21  # 1 month\n",
    "config['backtest']['walk_forward']['step_size'] = 7  # 1 week\n",
    "\n",
    "backtester = Backtester(config)\n",
    "\n",
    "backtest_results = backtester.run_backtest(\n",
    "    data=processed_data,\n",
    "    start_date=config['data']['start_date'],\n",
    "    end_date=config['data']['end_date']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Backtesting completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get results\n",
    "portfolio_df = pd.DataFrame(backtester.portfolio_history)\n",
    "trades_df = backtester.get_trade_analysis()\n",
    "\n",
    "print(f\"üìä Backtest Results Summary:\")\n",
    "print(f\"Portfolio records: {len(portfolio_df)}\")\n",
    "print(f\"Total trades: {len(trades_df)}\")\n",
    "\n",
    "if not portfolio_df.empty:\n",
    "    initial_value = config['backtest']['initial_capital']\n",
    "    final_value = portfolio_df['total_value'].iloc[-1] if 'total_value' in portfolio_df.columns else portfolio_df['portfolio_value'].iloc[-1]\n",
    "    total_return = (final_value - initial_value) / initial_value\n",
    "    \n",
    "    print(f\"\\nüí∞ PERFORMANCE METRICS\")\n",
    "    print(f\"Initial Capital: ${initial_value:,.2f}\")\n",
    "    print(f\"Final Value: ${final_value:,.2f}\")\n",
    "    print(f\"Total Return: {total_return:.2%}\")\n",
    "    \n",
    "    if not trades_df.empty and 'pnl' in trades_df.columns:\n",
    "        winning_trades = trades_df[trades_df['pnl'] > 0]\n",
    "        losing_trades = trades_df[trades_df['pnl'] <= 0]\n",
    "        win_rate = len(winning_trades) / len(trades_df)\n",
    "        \n",
    "        print(f\"Win Rate: {win_rate:.2%}\")\n",
    "        print(f\"Average Win: ${winning_trades['pnl'].mean():.2f}\") if len(winning_trades) > 0 else None\n",
    "        print(f\"Average Loss: ${losing_trades['pnl'].mean():.2f}\") if len(losing_trades) > 0 else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Portfolio performance visualization\n",
    "if not portfolio_df.empty:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Portfolio value over time\n",
    "    dates = pd.to_datetime(portfolio_df['date'])\n",
    "    values = portfolio_df['total_value'] if 'total_value' in portfolio_df.columns else portfolio_df['portfolio_value']\n",
    "    \n",
    "    axes[0, 0].plot(dates, values, linewidth=2, color='blue')\n",
    "    axes[0, 0].set_title('Portfolio Value Over Time')\n",
    "    axes[0, 0].set_ylabel('Portfolio Value ($)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Drawdown analysis\n",
    "    peak = values.expanding().max()\n",
    "    drawdown = (values - peak) / peak * 100\n",
    "    \n",
    "    axes[0, 1].fill_between(dates, drawdown, 0, alpha=0.7, color='red')\n",
    "    axes[0, 1].plot(dates, drawdown, linewidth=1, color='darkred')\n",
    "    axes[0, 1].set_title('Drawdown Analysis')\n",
    "    axes[0, 1].set_ylabel('Drawdown (%)')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Trade analysis\n",
    "    if not trades_df.empty and 'pnl' in trades_df.columns:\n",
    "        # P&L distribution\n",
    "        axes[1, 0].hist(trades_df['pnl'], bins=20, alpha=0.7, edgecolor='black')\n",
    "        axes[1, 0].axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "        axes[1, 0].axvline(trades_df['pnl'].mean(), color='green', linestyle='--', \n",
    "                          label=f'Mean: ${trades_df[\"pnl\"].mean():.2f}')\n",
    "        axes[1, 0].set_title('Trade P&L Distribution')\n",
    "        axes[1, 0].set_xlabel('P&L ($)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Cumulative P&L\n",
    "        cumulative_pnl = trades_df['pnl'].cumsum()\n",
    "        trade_numbers = range(1, len(cumulative_pnl) + 1)\n",
    "        axes[1, 1].plot(trade_numbers, cumulative_pnl, linewidth=2, color='green')\n",
    "        axes[1, 1].fill_between(trade_numbers, cumulative_pnl, 0, alpha=0.3, color='green')\n",
    "        axes[1, 1].set_title('Cumulative P&L')\n",
    "        axes[1, 1].set_xlabel('Trade Number')\n",
    "        axes[1, 1].set_ylabel('Cumulative P&L ($)')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance\n",
    "if model_manager.performance_metrics:\n",
    "    metrics_df = pd.DataFrame(model_manager.performance_metrics).T\n",
    "    \n",
    "    # Plot model comparison\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Validation accuracy\n",
    "    if 'val_accuracy' in metrics_df.columns:\n",
    "        metrics_df['val_accuracy'].plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.8)\n",
    "        axes.set_title('Model Validation Accuracy')\n",
    "        axes.set_ylabel('Accuracy')\n",
    "        axes.tick_params(axis='x', rotation=45)\n",
    "        axes.grid(True, alpha=0.3)\n",
    "    \n",
    "    # ROC AUC (if available)\n",
    "    if 'roc_auc' in metrics_df.columns:\n",
    "        metrics_df['roc_auc'].plot(kind='bar', ax=axes[1], color='lightcoral', alpha=0.8)\n",
    "        axes[asset:1].set_title('Model ROC AUC Score')\n",
    "        axes[asset:1].set_ylabel('ROC AUC')\n",
    "        axes[asset:1].tick_params(axis='x', rotation=45)\n",
    "        axes[asset:1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"üìä Model Performance Summary:\")\n",
    "    display_cols = ['train_accuracy', 'val_accuracy', 'roc_auc']\n",
    "    available_cols = [col for col in display_cols if col in metrics_df.columns]\n",
    "    print(metrics_df[available_cols].round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional risk metrics\n",
    "if not portfolio_df.empty and 'total_value' in portfolio_df.columns:\n",
    "    values = portfolio_df['total_value']\n",
    "    returns = values.pct_change().dropna()\n",
    "    \n",
    "    # Calculate risk metrics\n",
    "    volatility = returns.std() * np.sqrt(252)\n",
    "    max_drawdown = drawdown.min()\n",
    "    sharpe_ratio = (returns.mean() * 252) / volatility if volatility > 0 else 0\n",
    "    \n",
    "    # VaR calculation (5% and 1%)\n",
    "    var_95 = np.percentile(returns, 5)\n",
    "    var_99 = np.percentile(returns, 1)\n",
    "    \n",
    "    print(\"üìâ RISK ANALYSIS\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Annualized Volatility: {volatility:.2%}\")\n",
    "    print(f\"Maximum Drawdown: {abs(max_drawdown):.2%}\")\n",
    "    print(f\"Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "    print(f\"VaR (95%): {var_95:.2%}\")\n",
    "    print(f\"VaR (99%): {var_99:.2%}\")\n",
    "    \n",
    "    # Plot return distribution with VaR\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(returns, bins=50, alpha=0.7, density=True, edgecolor='black')\n",
    "    plt.axvline(var_95, color='red', linestyle='--', label=f'VaR 95%: {var_95:.2%}')\n",
    "    plt.axvline(var_99, color='darkred', linestyle='--', label=f'VaR 99%: {var_99:.2%}')\n",
    "    plt.axvline(returns.mean(), color='green', linestyle='-', label=f'Mean: {returns.mean():.2%}')\n",
    "    plt.title('Daily Returns Distribution with VaR')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Export Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'demo_results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Export data\n",
    "if not portfolio_df.empty:\n",
    "    portfolio_df.to_csv(f'{results_dir}/portfolio_history.csv', index=False)\n",
    "    print(f\"‚úÖ Portfolio history exported to {results_dir}/portfolio_history.csv\")\n",
    "\n",
    "if not trades_df.empty:\n",
    "    trades_df.to_csv(f'{results_dir}/trades.csv', index=False)\n",
    "    print(f\"‚úÖ Trades exported to {results_dir}/trades.csv\")\n",
    "\n",
    "# Export model metrics\n",
    "if model_manager.performance_metrics:\n",
    "    with open(f'{results_dir}/model_metrics.json', 'w') as f:\n",
    "        json.dump(model_manager.performance_metrics, f, indent=4, default=str)\n",
    "    print(f\"‚úÖ Model metrics exported to {results_dir}/model_metrics.json\")\n",
    "\n",
    "# Export configuration used\n",
    "with open(f'{results_dir}/config_used.json', 'w') as f:\n",
    "    json.dump(config, f, indent=4)\n",
    "    print(f\"‚úÖ Configuration exported to {results_dir}/config_used.json\")\n",
    "\n",
    "print(f\"\\nüìÅ All results saved to: {results_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Summary and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary report\n",
    "print(\"üìã TRADING STRATEGY PERFORMANCE SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if not portfolio_df.empty:\n",
    "    initial_capital = config['backtest']['initial_capital']\n",
    "    final_value = portfolio_df['total_value'].iloc[-1] if 'total_value' in portfolio_df.columns else portfolio_df['portfolio_value'].iloc[-1]\n",
    "    total_return = (final_value - initial_capital) / initial_capital\n",
    "    \n",
    "    print(f\"üìä FINANCIAL PERFORMANCE\")\n",
    "    print(f\"  Initial Capital: ${initial_capital:,.2f}\")\n",
    "    print(f\"  Final Portfolio Value: ${final_value:,.2f}\")\n",
    "    print(f\"  Total Return: {total_return:.2%}\")\n",
    "    print(f\"  Annualized Return: {(1 + total_return) ** (252 / len(portfolio_df)) - 1:.2%}\")\n",
    "    \n",
    "    if 'volatility' in locals():\n",
    "        print(f\"  Volatility: {volatility:.2%}\")\n",
    "        print(f\"  Sharpe Ratio: {sharpe_ratio:.2f}\")\n",
    "        print(f\"  Max Drawdown: {abs(max_drawdown):.2%}\")\n",
    "\n",
    "if not trades_df.empty:\n",
    "    winning_trades = len(trades_df[trades_df['pnl'] > 0])\n",
    "    total_trades = len(trades_df)\n",
    "    win_rate = winning_trades / total_trades\n",
    "    \n",
    "    print(f\"\\nüéØ TRADING STATISTICS\")\n",
    "    print(f\"  Total Trades: {total_trades}\")\n",
    "    print(f\"  Winning Trades: {winning_trades}\")\n",
    "    print(f\"  Win Rate: {win_rate:.2%}\")\n",
    "    print(f\"  Average Trade P&L: ${trades_df['pnl'].mean():.2f}\")\n",
    "    print(f\"  Best Trade: ${trades_df['pnl'].max():.2f}\")\n",
    "    print(f\"  Worst Trade: ${trades_df['pnl'].min():.2f}\")\n",
    "\n",
    "if model_manager.performance_metrics:\n",
    "    print(f\"\\nü§ñ MODEL PERFORMANCE\")\n",
    "    for model_name, metrics in model_manager.performance_metrics.items():\n",
    "        print(f\"  {model_name.upper()}:\")\n",
    "        print(f\"    Validation Accuracy: {metrics.get('val_accuracy', 0):.2%}\")\n",
    "        if 'roc_auc' in metrics:\n",
    "            print(f\"    ROC AUC: {metrics.get('roc_auc', 0):.3f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è IMPORTANT DISCLAIMERS:\")\n",
    "print(f\"  ‚Ä¢ This is a demonstration for educational purposes only\")\n",
    "print(f\"  ‚Ä¢ Past performance does not guarantee future results\")\n",
    "print(f\"  ‚Ä¢ All trading involves substantial risk of loss\")\n",
    "print(f\"  ‚Ä¢ Thoroughly backtest any strategy before live deployment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated the complete ML trading strategy workflow:\n",
    "\n",
    "‚úÖ **Data Pipeline**: Automated data fetching and feature engineering  \n",
    "‚úÖ **Model Training**: Multiple ML models with performance evaluation  \n",
    "‚úÖ **Backtesting**: Realistic historical simulation with transaction costs  \n",
    "‚úÖ **Analysis**: Comprehensive performance metrics and visualizations  \n",
    "‚úÖ **Export**: Results saved for further analysis  \n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Hyperparameter Tuning**: Use `GridSearchCV` for optimal parameters\n",
    "2. **Extended Backtesting**: Test on longer periods and more assets\n",
    "3. **Risk Analysis**: Implement stress testing and scenario analysis\n",
    "4. **Live Trading**: Deploy strategy with paper trading first\n",
    "\n",
    "### Important Notes\n",
    "\n",
    "‚ö†Ô∏è **This is for educational purposes only**  \n",
    "‚ö†Ô∏è **Past performance does not guarantee future results**  \n",
    "‚ö†Ô∏è **Always test strategies thoroughly before live deployment**  \n",
    "‚ö†Ô∏è **Consider transaction costs, slippage, and market impact**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

